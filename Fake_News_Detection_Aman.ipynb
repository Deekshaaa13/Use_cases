{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fake News Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fake news is one of the biggest problems because it leads to a lot of misinformation in a particular region. Most of the time, spreading false news about a community’s political and religious beliefs can lead to riots and violence as you must have seen in the country where you live. So, to detect fake news, we can find relationships between the fake news headlines so that we can train a machine learning model that can tell us whether a particular piece of information is fake or real by simply observing the headline in the news."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fake News Detection using Python\n",
    "The dataset I am using here for the fake news detection task has data about the news title, news content, and a column known as label that shows whether the news is fake or real. So we can use this dataset to find relationships between fake and real news headlines to understand what type of headlines are in most fake news. So let’s import the necessary Python libraries and the dataset that we need for this task:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Unnamed: 0                                              title  \\\n",
      "0        8476                       You Can Smell Hillary’s Fear   \n",
      "1       10294  Watch The Exact Moment Paul Ryan Committed Pol...   \n",
      "2        3608        Kerry to go to Paris in gesture of sympathy   \n",
      "3       10142  Bernie supporters on Twitter erupt in anger ag...   \n",
      "4         875   The Battle of New York: Why This Primary Matters   \n",
      "\n",
      "                                                text label  \n",
      "0  Daniel Greenfield, a Shillman Journalism Fello...  FAKE  \n",
      "1  Google Pinterest Digg Linkedin Reddit Stumbleu...  FAKE  \n",
      "2  U.S. Secretary of State John F. Kerry said Mon...  REAL  \n",
      "3  — Kaydee King (@KaydeeKing) November 9, 2016 T...  FAKE  \n",
      "4  It's primary day in New York and front-runners...  REAL  \n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv(\"fake_or_real_news.csv\")\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This dataset is very large and luckily it still has no missing values so without wasting any time let’s use the title column as the feature we need to train a machine learning model and the label column as the values we want to predict:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=np.array(data['title'])\n",
    "y=np.array(data['label'])\n",
    "cv=CountVectorizer()\n",
    "x=cv.fit_transform(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<6335x10071 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 63910 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let’s separate the dataset into training and testing sets, and then I’ll use the Multinomial Naive Bayes algorithm to train the fake news detection model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8121546961325967\n"
     ]
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test=train_test_split(x,y, test_size=0.2, random_state=0)\n",
    "model=MultinomialNB()\n",
    "model.fit(x_train,y_train)\n",
    "print(model.score(x_test,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let’s test this model. To test our trained model, I’ll first write down the title of any news item found on google news to see if our model predicts that the news is real or not:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['FAKE']\n"
     ]
    }
   ],
   "source": [
    "news_headline = \"Cow dung can cure Corona Virus\"\n",
    "data=cv.transform([news_headline]).toarray()\n",
    "print(model.predict(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
